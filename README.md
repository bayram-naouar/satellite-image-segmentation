# ğŸ›°ï¸ Satellite Image Segmentation with U-Net

A complete deep learning pipeline for segmenting satellite images using a U-Net model, including data augmentation, training, and an interactive Streamlit playground.

---

## ğŸ“ Project Structure

```
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ Image/                  # Original input images
â”‚   â”œâ”€â”€ Mask/                   # Corresponding masks
â”‚   â”œâ”€â”€ augmented_images/       # Augmented input images
â”‚   â””â”€â”€ augmented_masks/        # Augmented masks
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ final_model.h5          # Final saved model
â”‚   â””â”€â”€ model_best.h5           # Best checkpoint model
â”œâ”€â”€ app.py                      # Streamlit app for testing images
â”œâ”€â”€ dataset.py                  # Dataset class and preprocessing logic
â”œâ”€â”€ augment_data.py             # Script to augment images and masks
â”œâ”€â”€ train.py                    # Model training and loss plotting
â”œâ”€â”€ config.yaml                 # Configuration file for parameters
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ .gitignore                  # Files to ignore in Git
```

---

## âš™ï¸ How to Use

1. **(Optional)** Augment the dataset:
```bash
python augment_data.py
```

2. **Train the model**:
```bash
python train.py
```

3. **Run the Streamlit app**:
```bash
streamlit run app.py
```

---

## ğŸ§ª Features

- U-Net architecture with optional Dropout and BatchNormalization
- Combined Binary Cross-Entropy and Dice Loss
- Real-time inference with Streamlit
- YAML-based config for easy experimentation

---

## ğŸ”§ Configuration

All important settings for data paths, training behavior, and model architecture are centralized in the config.yaml file.
This allows you to easily customize the project without modifying the core scripts.
You can change dataset directories (```image_dir```, ```mask_dir```, ```augmented_image_dir```, ```augmented_mask_dir```) or enable/disable data shuffling.
Under the training section, you can tune hyperparameters such as ```batch_size```, ```image_size```, ```number of epochs```, ```learning_rate```, and ```dropout_rate```.
If you want to include augmented data during training, simply set ```use_augment``` to ```true```.
Finally, the model section lets you specify which architecture to use (currently supports "unet").
Adjust these values as needed to experiment with performance or scale the pipeline to different datasets.

---

## ğŸ“¦ Setup

Install all dependencies with:
```bash
pip install -r requirements.txt
```

---

## ğŸŒ About

Iâ€™m a newly arrived permanent resident in Canada, and this project showcases my practical knowledge in deep learning and computer vision. I'm a fast learner passionate about solving real-world problems.

---

## âœ‰ï¸ Contact

Feel free to connect with me on [LinkedIn](https://www.linkedin.com/in/bayramnaouar95) or via email: bayram.naouar@gmail.com
